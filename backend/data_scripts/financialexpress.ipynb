{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 1582155,
     "status": "ok",
     "timestamp": 1732016252501,
     "user": {
      "displayName": "Saurabh Saini",
      "userId": "13411094811282468436"
     },
     "user_tz": -330
    },
    "id": "ntT4774gKgtp",
    "outputId": "a41f7daf-7319-4f8a-b9ee-16d66248f03e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages: 100%|██████████| 1558/1558 [26:21<00:00,  1.02s/it]\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_807a3bf1-f2b0-43ce-8dcb-1a1398210d4e\", \"articles1.json\", 7302466)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://www.financialexpress.com/archive/page/7779/\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "articles = []\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "\n",
    "for i in tqdm(range(7779, 6221, -1), desc=\"Processing pages\"):\n",
    "\n",
    "  url = f\"http://www.financialexpress.com/archive/page/{i}/\"\n",
    "  r = requests.get(url, headers=headers)\n",
    "  soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "  # Get all \"entry-wrapper\" divs\n",
    "  listdiv = soup.find('div', class_='wp-block-newspack-blocks-ie-stories is-style-borders resize-image119x67 ie-stories show-image image-alignright ts-3 is-3 is-landscape is-style-borders resize-image119x67')\n",
    "  entry_wrappers = listdiv.find_all('div', class_='entry-wrapper')\n",
    "\n",
    "  for entry_wrapper in entry_wrappers:\n",
    "\n",
    "    try:\n",
    "\n",
    "      # Get title and url from <a> tag of 'entry-title' div\n",
    "      title = entry_wrapper.find('h2', class_='entry-title').find('a').text\n",
    "      url = entry_wrapper.find('h2', class_='entry-title').find('a')['href']\n",
    "\n",
    "      # Get date and auther\n",
    "      date = entry_wrapper.find('div', class_='entry-meta').find('time', class_='entry-date published')['datetime']\n",
    "      # add none if no auther\n",
    "      auther = entry_wrapper.find('div', class_='entry-meta').find('a')\n",
    "      if auther:\n",
    "        auther = auther.text\n",
    "      else:\n",
    "        auther = 'Unknown'\n",
    "\n",
    "      article = {\n",
    "          'auther': auther,\n",
    "          'date': date,\n",
    "          'title': title,\n",
    "          'url': url\n",
    "      }\n",
    "      articles.append(article)\n",
    "\n",
    "    except Exception as e:\n",
    "      print(f\"Error processing article on page {i}: {e}\")\n",
    "\n",
    "  # Save to file every 50 iterations\n",
    "  if i % 50 == 0:\n",
    "      # Check if the file exists and read the existing data\n",
    "      if os.path.exists('articles1.json'):\n",
    "          with open('articles1.json', 'r') as f:\n",
    "              existing_articles = json.load(f)\n",
    "      else:\n",
    "          existing_articles = []\n",
    "\n",
    "      # Merge the new articles with the existing ones\n",
    "      existing_articles.extend(articles)\n",
    "\n",
    "      # Write the updated data back to the file\n",
    "      with open('articles1.json', 'w') as f:\n",
    "          json.dump(existing_articles, f, indent=4)\n",
    "\n",
    "      # Clear the articles list to free up memory\n",
    "      articles.clear()\n",
    "\n",
    "if articles:\n",
    "  if os.path.exists('articles1.json'):\n",
    "    with open('articles1.json', 'r') as f:\n",
    "      existing_articles = json.load(f)\n",
    "  else:\n",
    "    existing_articles = []\n",
    "\n",
    "    # Merge the new articles with the existing ones\n",
    "    existing_articles.extend(articles)\n",
    "\n",
    "    # Write the updated data back to the file\n",
    "    with open('articles1.json', 'w') as f:\n",
    "      json.dump(existing_articles, f, indent=4)\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "# Download the JSON file\n",
    "files.download('articles1.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 777,
     "status": "ok",
     "timestamp": 1732025656239,
     "user": {
      "displayName": "Saurabh Saini",
      "userId": "13411094811282468436"
     },
     "user_tz": -330
    },
    "id": "v5vBKBLa8Hlx",
    "outputId": "4867cace-1d94-4fee-c52e-84e07f89f1a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27529\n",
      "{'auther': 'Saumitra Chaudhury', 'date': '2002-01-21T00:00:00+05:30', 'title': 'A complicated re-telling ', 'url': 'https://www.financialexpress.com/archive/a-complicated-re-telling/44974/'}\n",
      "{'auther': 'Economy Bureau', 'date': '2008-08-22T00:31:30+05:30', 'title': 'No let-up, inflation hits 16-yr high of 12.63% ', 'url': 'https://www.financialexpress.com/archive/no-let-up-inflation-hits-16-yr-high-of-1263/351853/'}\n"
     ]
    }
   ],
   "source": [
    "# read the file in a list\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import json\n",
    "\n",
    "articles = []\n",
    "with open('articles1.json', 'r') as f:\n",
    "  articles = json.load(f)\n",
    "\n",
    "print(len(articles))\n",
    "print(articles[0])\n",
    "print(articles[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNupL3HPRgQW"
   },
   "outputs": [],
   "source": [
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Function to process an individual article\n",
    "def fetch_article_content(article, headers):\n",
    "    try:\n",
    "        r = requests.get(article['url'], headers=headers)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        content = soup.find('div', id='pcl-full-content')\n",
    "        if content:\n",
    "          article['content'] = content.text\n",
    "        else:\n",
    "          article['content'] = ''\n",
    "          print(f\"Error at url: {article['url']}\")\n",
    "    except Exception as e:\n",
    "        article['content'] = ''\n",
    "        print(f\"For date: {article['date']}, Error fetching {article['url']}: {e}\")\n",
    "    return article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4659538,
     "status": "ok",
     "timestamp": 1732030316359,
     "user": {
      "displayName": "Saurabh Saini",
      "userId": "13411094811282468436"
     },
     "user_tz": -330
    },
    "id": "MdLH3_sBrbDU",
    "outputId": "b7a1af90-8367-4471-e46b-03a41f5662fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles: 100%|██████████| 27529/27529 [1:15:38<00:00,  6.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Using ThreadPoolExecutor for parallel processing\n",
    "with ThreadPoolExecutor(max_workers=64) as executor:\n",
    "    future_to_article = {executor.submit(fetch_article_content, article, headers): article for article in articles}\n",
    "\n",
    "    for future in tqdm(as_completed(future_to_article), total=len(articles), desc=\"Processing articles\"):\n",
    "        result = future.result()  # This will raise any exception that occurred during the function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srQ3-njF5O4v"
   },
   "outputs": [],
   "source": [
    "with open('content1.json', 'w') as f:\n",
    "  json.dump(articles, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1732030320621,
     "user": {
      "displayName": "Saurabh Saini",
      "userId": "13411094811282468436"
     },
     "user_tz": -330
    },
    "id": "_lWrdXh55Ugd",
    "outputId": "68a580b4-e085-41b3-b56f-21513770ee8a"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_52b32974-3c4f-4955-bf6f-b982fefecaa8\", \"content1.json\", 75427238)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download('content1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "executionInfo": {
     "elapsed": 289733,
     "status": "error",
     "timestamp": 1732042727001,
     "user": {
      "displayName": "Saurabh Saini",
      "userId": "13411094811282468436"
     },
     "user_tz": -330
    },
    "id": "stEs-QDamQ8b",
    "outputId": "fdd0817d-262b-42eb-ad27-2e86d638c5bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages: 100%|██████████| 5304/5304 [14:12<00:00,  6.22it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aafb1364dfb7>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'articles6.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m           \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# https://www.financialexpress.com/business/industry/page/5304/\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import json\n",
    "articles = []\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Function to process a single page\n",
    "def fetch_page_content(i):\n",
    "    try:\n",
    "        url = f\"https://www.financialexpress.com/business/industry/page/{i}/\"\n",
    "        r = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "        listdiv = soup.find('div', class_='wp-block-newspack-blocks-ie-stories is-style-borders resize-image119x67 ie-stories show-image image-alignright ts-3 is-3 is-landscape is-style-borders resize-image119x67')\n",
    "        entry_wrappers = listdiv.find_all('div', class_='entry-wrapper')\n",
    "\n",
    "        page_articles = []\n",
    "        for entry_wrapper in entry_wrappers:\n",
    "            try:\n",
    "                title = entry_wrapper.find('h2', class_='entry-title').find('a').text\n",
    "                url = entry_wrapper.find('h2', class_='entry-title').find('a')['href']\n",
    "                # date = entry_wrapper.find('div', class_='entry-meta').find('time', class_='entry-date published')['datetime']\n",
    "                auther = entry_wrapper.find('div', class_='entry-meta').find('a')\n",
    "                auther = auther.text if auther else 'Unknown'\n",
    "\n",
    "                article = {\n",
    "                    'auther': auther,\n",
    "                    'title': title,\n",
    "                    'url': url\n",
    "                }\n",
    "                page_articles.append(article)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing article on page {i}: {e}\")\n",
    "                print(f\"Error at title: {title}\")\n",
    "                continue\n",
    "        return page_articles\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching page {i}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Parallel execution\n",
    "with ThreadPoolExecutor(max_workers=64) as executor:  # Adjust `max_workers` as needed\n",
    "    futures = [executor.submit(fetch_page_content, i) for i in range(5304, 0, -1)]\n",
    "\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing pages\"):\n",
    "        articles.extend(future.result())  # Collect articles from each completed future\n",
    "\n",
    "\n",
    "with open('articles6.json', 'w') as f:\n",
    "          json.dump(articles, f, indent=4)\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "# Download the JSON file\n",
    "files.download('articles6.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSRFQoOht6t2"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('articles6.json', 'w') as f:\n",
    "          json.dump(articles, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 731,
     "status": "ok",
     "timestamp": 1732043560040,
     "user": {
      "displayName": "Saurabh Saini",
      "userId": "13411094811282468436"
     },
     "user_tz": -330
    },
    "id": "zDEz-8DdpMip",
    "outputId": "75c7a91b-3aca-46f1-bd53-53898a96d2ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95472\n",
      "{'auther': 'FE Online', 'title': 'Yahoo, Flipkart launch co-branded shopping site ', 'url': 'https://www.financialexpress.com/business/industry-yahoo-flipkart-launch-co-branded-site-8519/'}\n",
      "{'auther': 'Viveat Susan Pinto', 'title': 'Imagicaaworld looks to double theme parks in six years ', 'url': 'https://www.financialexpress.com/business/industry-imagicaaworld-looks-to-double-theme-parks-in-six-years-3653181/'}\n"
     ]
    }
   ],
   "source": [
    "# read the file in a list\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "\n",
    "articles = []\n",
    "with open('articles6.json', 'r') as f:\n",
    "  articles = json.load(f)\n",
    "\n",
    "print(len(articles))\n",
    "print(articles[0])\n",
    "print(articles[-1])\n",
    "\n",
    "def convert_to_iso8601(datetime_str):\n",
    "    dt = datetime.strptime(datetime_str.strip(), \"%d-%m-%Y at %H:%M IST\")\n",
    "    ist_timezone = pytz.timezone('Asia/Kolkata')\n",
    "    dt_ist = ist_timezone.localize(dt)\n",
    "    iso8601_format = dt_ist.isoformat()\n",
    "\n",
    "    return iso8601_format\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Function to process an individual article\n",
    "def fetch_article_content(article):\n",
    "    try:\n",
    "        r = requests.get(article['url'], headers=headers)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "        date_div = soup.find('div', class_='ie-first-publish')\n",
    "        if date_div:\n",
    "          date_span = date_div.find('span')\n",
    "          if date_span:\n",
    "            article['date'] = convert_to_iso8601(date_span.text)\n",
    "          else:\n",
    "            article['date'] = ''\n",
    "            print(f\"No Date at url: {article['url']}\")\n",
    "        else:\n",
    "          article['date'] = ''\n",
    "          print(f\"No Date at url: {article['url']}\")\n",
    "\n",
    "        content_div = soup.find('div', id='pcl-full-content')\n",
    "        combined_text = \"\"\n",
    "        if content_div:\n",
    "          top_level_p_tags = content_div.find_all('p', recursive=False)\n",
    "          combined_text = \" \".join(p.get_text() for p in top_level_p_tags)\n",
    "          article['content'] = combined_text\n",
    "        else:\n",
    "          article['content'] = ''\n",
    "          print(f\"Error at url: {article['url']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        article['content'] = ''\n",
    "        print(f\"For date: {article['date']}, Error fetching {article['url']}: {e}\")\n",
    "    return article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "executionInfo": {
     "elapsed": 13431511,
     "status": "ok",
     "timestamp": 1732057354648,
     "user": {
      "displayName": "Saurabh Saini",
      "userId": "13411094811282468436"
     },
     "user_tz": -330
    },
    "id": "fnoYJnXu0miu",
    "outputId": "f97d87e1-50c2-4336-cb43-69365e273f96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  77%|███████▋  | 73955/95472 [2:54:04<11:56, 30.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Date at url: https://www.financialexpress.com/sponsored/schneider-electric/govt-proposal-of-rs-7000-pli-for-it-hardware-insignificant-at-least-rs-20000-cr-needed-mait/2183120/\n",
      "Error at url: https://www.financialexpress.com/sponsored/schneider-electric/govt-proposal-of-rs-7000-pli-for-it-hardware-insignificant-at-least-rs-20000-cr-needed-mait/2183120/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles: 100%|██████████| 95472/95472 [3:46:28<00:00,  7.03it/s]\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_09337917-abf9-4b73-ae04-616896a49d2c\", \"content6.json\", 276878068)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using ThreadPoolExecutor for parallel processing\n",
    "with ThreadPoolExecutor(max_workers=64) as executor:\n",
    "    future_to_article = {executor.submit(fetch_article_content, article): article for article in articles}\n",
    "\n",
    "    for future in tqdm(as_completed(future_to_article), total=len(articles), desc=\"Processing articles\"):\n",
    "        result = future.result()  # This will raise any exception that occurred during the function call\n",
    "\n",
    "with open('content6.json', 'w') as f:\n",
    "  json.dump(articles, f, indent=4)\n",
    "\n",
    "from google.colab import files\n",
    "files.download('content6.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1107,
     "status": "ok",
     "timestamp": 1732276306600,
     "user": {
      "displayName": "Saurabh Saini",
      "userId": "13411094811282468436"
     },
     "user_tz": -330
    },
    "id": "OgkQExRNtFFc",
    "outputId": "33f5849d-f330-450c-a287-585e3fa0f984"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADANIPORTS',\n",
       " 'ASIANPAINT',\n",
       " 'AXISBANK',\n",
       " 'BAJAJ-AUTO',\n",
       " 'BAJAJFINSV',\n",
       " 'BAJFINANCE',\n",
       " 'BHARTIARTL',\n",
       " 'BRITANNIA',\n",
       " 'BPCL',\n",
       " 'COALINDIA',\n",
       " 'EICHERMOT',\n",
       " 'DRREDDY',\n",
       " 'GAIL',\n",
       " 'GRASIM',\n",
       " 'CIPLA',\n",
       " 'HCLTECH',\n",
       " 'HDFC',\n",
       " 'HDFCBANK',\n",
       " 'HEROMOTOCO',\n",
       " 'HINDUNILVR',\n",
       " 'HINDALCO',\n",
       " 'ICICIBANK',\n",
       " 'INDUSINDBK',\n",
       " 'INFY',\n",
       " 'IOC',\n",
       " 'ITC',\n",
       " 'JSWSTEEL',\n",
       " 'KOTAKBANK',\n",
       " 'LT',\n",
       " 'MARUTI',\n",
       " 'MM',\n",
       " 'NESTLEIND',\n",
       " 'NTPC',\n",
       " 'ONGC',\n",
       " 'POWERGRID',\n",
       " 'RELIANCE',\n",
       " 'SBIN',\n",
       " 'SHREECEM',\n",
       " 'SUNPHARMA',\n",
       " 'TATAMOTORS',\n",
       " 'TATASTEEL',\n",
       " 'TCS',\n",
       " 'TECHM',\n",
       " 'TITAN',\n",
       " 'ULTRACEMCO',\n",
       " 'UPL',\n",
       " 'VEDL',\n",
       " 'WIPRO',\n",
       " 'ZEEL',\n",
       " '']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt: copy names of all the files to a list from the directory /content/drive/MyDrive/stocks\n",
    "\n",
    "import os\n",
    "\n",
    "def get_filenames(directory):\n",
    "  \"\"\"\n",
    "  Returns a list of filenames in the specified directory.\n",
    "  \"\"\"\n",
    "  filenames = []\n",
    "  for filename in os.listdir(directory):\n",
    "    filename = filename.split('.')[0]\n",
    "    filenames.append(filename)\n",
    "  return filenames\n",
    "\n",
    "# Example usage:\n",
    "directory_path = '/content/drive/MyDrive/stocks'\n",
    "file_names = get_filenames(directory_path)\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mg61VoH2tKsP"
   },
   "outputs": [],
   "source": [
    "stock_companies = {\n",
    "    'ADANIPORTS': ['ADANIPORTS', 'Adani Ports'],\n",
    "    'ASIANPAINT': ['ASIANPAINT', 'Asian Paints'],\n",
    "    'AXISBANK': ['AXISBANK', 'Axis Bank'],\n",
    "    'BAJAJ-AUTO': ['BAJAJ-AUTO', 'Bajaj Auto'],\n",
    "    'BAJAJFINSV': ['BAJAJFINSV', 'Bajaj Finserv'],\n",
    "    'BAJFINANCE': ['BAJFINANCE', 'Bajaj Finance'],\n",
    "    'BHARTIARTL': ['BHARTIARTL', 'Bharti Airtel', 'Airtel'],\n",
    "    'BRITANNIA': ['BRITANNIA', 'Britannia Industries'],\n",
    "    'BPCL': ['BPCL', 'Bharat Petroleum'],\n",
    "    'COALINDIA': ['COALINDIA', 'Coal India'],\n",
    "    'EICHERMOT': ['EICHERMOT', 'Eicher Motors'],\n",
    "    'DRREDDY': ['DRREDDY', \"Dr. Reddy's Laboratories\"],\n",
    "    'GAIL': ['GAIL', 'Gas Authority of India'],\n",
    "    'GRASIM': ['GRASIM', 'Grasim Industries'],\n",
    "    'CIPLA': ['CIPLA', 'Cipla Limited'],\n",
    "    'HCLTECH': ['HCLTECH', 'HCL Technologies'],\n",
    "    'HDFC': ['HDFC', 'Housing Development Finance Corporation'],\n",
    "    'HDFCBANK': ['HDFCBANK', 'HDFC Bank'],\n",
    "    'HEROMOTOCO': ['HEROMOTOCO', 'Hero MotoCorp'],\n",
    "    'HINDUNILVR': ['HINDUNILVR', 'Hindustan Unilever', 'HUL'],\n",
    "    'HINDALCO': ['HINDALCO', 'Hindalco Industries'],\n",
    "    'ICICIBANK': ['ICICIBANK', 'ICICI Bank'],\n",
    "    'INDUSINDBK': ['INDUSINDBK', 'IndusInd Bank'],\n",
    "    'INFY': ['INFY', 'Infosys'],\n",
    "    'IOC': ['IOC', 'Indian Oil'],\n",
    "    'ITC': ['ITC', 'ITC Limited'],\n",
    "    'JSWSTEEL': ['JSWSTEEL', 'JSW Steel'],\n",
    "    'KOTAKBANK': ['KOTAKBANK', 'Kotak Mahindra Bank'],\n",
    "    'LT': ['LT', 'Larsen & Toubro'],\n",
    "    'MARUTI': ['MARUTI', 'Maruti Suzuki'],\n",
    "    'MM': ['MM', 'Mahindra & Mahindra'],\n",
    "    'NESTLEIND': ['NESTLEIND', 'Nestle India'],\n",
    "    'NTPC': ['NTPC', 'NTPC Limited'],\n",
    "    'ONGC': ['ONGC', 'Oil and Natural Gas Corporation'],\n",
    "    'POWERGRID': ['POWERGRID', 'Power Grid Corporation'],\n",
    "    'RELIANCE': ['RELIANCE', 'Reliance Industries'],\n",
    "    'SBIN': ['SBIN', 'State Bank of India'],\n",
    "    'SHREECEM': ['SHREECEM', 'Shree Cement'],\n",
    "    'SUNPHARMA': ['SUNPHARMA', 'Sun Pharma'],\n",
    "    'TATAMOTORS': ['TATAMOTORS', 'Tata Motors'],\n",
    "    'TATASTEEL': ['TATASTEEL', 'Tata Steel'],\n",
    "    'TCS': ['TCS', 'Tata Consultancy Services'],\n",
    "    'TECHM': ['TECHM', 'Tech Mahindra'],\n",
    "    'TITAN': ['TITAN', 'Titan Company'],\n",
    "    'ULTRACEMCO': ['ULTRACEMCO', 'UltraTech Cement'],\n",
    "    'UPL': ['UPL', 'UPL Limited'],\n",
    "    'VEDL': ['VEDL', 'Vedanta'],\n",
    "    'WIPRO': ['WIPRO', 'Wipro Limited'],\n",
    "    'ZEEL': ['ZEEL', 'Zee Entertainment']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1732277149731,
     "user": {
      "displayName": "Saurabh Saini",
      "userId": "13411094811282468436"
     },
     "user_tz": -330
    },
    "id": "TrGJTps3wRE8",
    "outputId": "a9e2feee-664f-44a3-dea0-645c027d68ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADANIPORTS': ['adaniports', 'adani ports'],\n",
       " 'ASIANPAINT': ['asianpaint', 'asian paints'],\n",
       " 'AXISBANK': ['axisbank', 'axis bank'],\n",
       " 'BAJAJ-AUTO': ['bajaj-auto', 'bajaj auto'],\n",
       " 'BAJAJFINSV': ['bajajfinsv', 'bajaj finserv'],\n",
       " 'BAJFINANCE': ['bajfinance', 'bajaj finance'],\n",
       " 'BHARTIARTL': ['bhartiartl', 'bharti airtel', 'airtel'],\n",
       " 'BRITANNIA': ['britannia', 'britannia industries'],\n",
       " 'BPCL': ['bpcl', 'bharat petroleum'],\n",
       " 'COALINDIA': ['coalindia', 'coal india'],\n",
       " 'EICHERMOT': ['eichermot', 'eicher motors'],\n",
       " 'DRREDDY': ['drreddy', \"dr. reddy's laboratories\"],\n",
       " 'GAIL': ['gail', 'gas authority of india'],\n",
       " 'GRASIM': ['grasim', 'grasim industries'],\n",
       " 'CIPLA': ['cipla', 'cipla limited'],\n",
       " 'HCLTECH': ['hcltech', 'hcl technologies'],\n",
       " 'HDFC': ['hdfc', 'housing development finance corporation'],\n",
       " 'HDFCBANK': ['hdfcbank', 'hdfc bank'],\n",
       " 'HEROMOTOCO': ['heromotoco', 'hero motocorp'],\n",
       " 'HINDUNILVR': ['hindunilvr', 'hindustan unilever', 'hul'],\n",
       " 'HINDALCO': ['hindalco', 'hindalco industries'],\n",
       " 'ICICIBANK': ['icicibank', 'icici bank'],\n",
       " 'INDUSINDBK': ['indusindbk', 'indusind bank'],\n",
       " 'INFY': ['infy', 'infosys'],\n",
       " 'IOC': ['ioc', 'indian oil'],\n",
       " 'ITC': ['itc', 'itc limited'],\n",
       " 'JSWSTEEL': ['jswsteel', 'jsw steel'],\n",
       " 'KOTAKBANK': ['kotakbank', 'kotak mahindra bank'],\n",
       " 'LT': ['lt', 'larsen & toubro'],\n",
       " 'MARUTI': ['maruti', 'maruti suzuki'],\n",
       " 'MM': ['mm', 'mahindra & mahindra'],\n",
       " 'NESTLEIND': ['nestleind', 'nestle india'],\n",
       " 'NTPC': ['ntpc', 'ntpc limited'],\n",
       " 'ONGC': ['ongc', 'oil and natural gas corporation'],\n",
       " 'POWERGRID': ['powergrid', 'power grid corporation'],\n",
       " 'RELIANCE': ['reliance', 'reliance industries'],\n",
       " 'SBIN': ['sbin', 'state bank of india'],\n",
       " 'SHREECEM': ['shreecem', 'shree cement'],\n",
       " 'SUNPHARMA': ['sunpharma', 'sun pharma'],\n",
       " 'TATAMOTORS': ['tatamotors', 'tata motors'],\n",
       " 'TATASTEEL': ['tatasteel', 'tata steel'],\n",
       " 'TCS': ['tcs', 'tata consultancy services'],\n",
       " 'TECHM': ['techm', 'tech mahindra'],\n",
       " 'TITAN': ['titan', 'titan company'],\n",
       " 'ULTRACEMCO': ['ultracemco', 'ultratech cement'],\n",
       " 'UPL': ['upl', 'upl limited'],\n",
       " 'VEDL': ['vedl', 'vedanta'],\n",
       " 'WIPRO': ['wipro', 'wipro limited'],\n",
       " 'ZEEL': ['zeel', 'zee entertainment']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = {}\n",
    "\n",
    "for stock, names in stock_companies.items():\n",
    "  companies[stock]=[name.lower() for name in names]\n",
    "\n",
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRuMNq7ax__8"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/content/drive/MyDrive/articles/content1.json', 'r') as f:\n",
    "  articles = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 32702,
     "status": "ok",
     "timestamp": 1732277866079,
     "user": {
      "displayName": "Saurabh Saini",
      "userId": "13411094811282468436"
     },
     "user_tz": -330
    },
    "id": "5ANkDr-LyOdl",
    "outputId": "1e58a0b8-8e5b-443c-9f2d-d8342ba0248d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles: 100%|██████████| 27529/27529 [00:32<00:00, 857.21it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "company_articles = {company:[] for company in companies}\n",
    "\n",
    "for article in tqdm(articles, desc=\"Processing articles\"):\n",
    "  for company, names in companies.items():\n",
    "    for name in names:\n",
    "      if name in article['title'].lower():\n",
    "        company_articles[company].append(article)\n",
    "      elif name in article['content'].lower():\n",
    "        company_articles[company].append(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1732277885428,
     "user": {
      "displayName": "Saurabh Saini",
      "userId": "13411094811282468436"
     },
     "user_tz": -330
    },
    "id": "fYvGkgDkzqCH",
    "outputId": "6e42f09c-afed-4921-9982-cce90710a42d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADANIPORTS: 4\n",
      "ASIANPAINT: 50\n",
      "AXISBANK: 150\n",
      "BAJAJ-AUTO: 168\n",
      "BAJAJFINSV: 6\n",
      "BAJFINANCE: 3\n",
      "BHARTIARTL: 845\n",
      "BRITANNIA: 74\n",
      "BPCL: 324\n",
      "COALINDIA: 140\n",
      "EICHERMOT: 50\n",
      "DRREDDY: 0\n",
      "GAIL: 226\n",
      "GRASIM: 120\n",
      "CIPLA: 70\n",
      "HCLTECH: 93\n",
      "HDFC: 568\n",
      "HDFCBANK: 337\n",
      "HEROMOTOCO: 53\n",
      "HINDUNILVR: 709\n",
      "HINDALCO: 137\n",
      "ICICIBANK: 566\n",
      "INDUSINDBK: 42\n",
      "INFY: 515\n",
      "IOC: 673\n",
      "ITC: 1338\n",
      "JSWSTEEL: 117\n",
      "KOTAKBANK: 88\n",
      "LT: 18272\n",
      "MARUTI: 435\n",
      "MM: 17019\n",
      "NESTLEIND: 13\n",
      "NTPC: 347\n",
      "ONGC: 490\n",
      "POWERGRID: 74\n",
      "RELIANCE: 2428\n",
      "SBIN: 477\n",
      "SHREECEM: 25\n",
      "SUNPHARMA: 78\n",
      "TATAMOTORS: 409\n",
      "TATASTEEL: 360\n",
      "TCS: 409\n",
      "TECHM: 34\n",
      "TITAN: 126\n",
      "ULTRACEMCO: 22\n",
      "UPL: 1576\n",
      "VEDL: 84\n",
      "WIPRO: 308\n",
      "ZEEL: 23\n"
     ]
    }
   ],
   "source": [
    "for company, articles in company_articles.items():\n",
    "  print(f\"{company}: {len(articles)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO1DEhmkQf0roUQUvm8fK9O",
   "mount_file_id": "1sBz1NZbjfONPWF5HwrD-aXLMPMx5iN8k",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
